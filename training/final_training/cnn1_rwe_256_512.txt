================================================================================
Command Line:
	train_classifier.py cnn rwe /mnt/data/RWE -rwew 256 -rwed 512 -t 0.1 -roc -nno adadelta -nnb 1000 -nne 200 -nnl training/nnlayers/cnn1.txt
================================================================================
================================================================================
Loading data...
================================================================================
================================================================================
Feature Type: rwe
	Window Size: 256
	Data points: 512
Number of features: 512
================================================================================
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:


================================================================================
Classifier Type: Convolutional Neural Network (cnn)
================================================================================
Training Class Count:
================================================================================
	Virus       9000
	Worm        9000
	PUA         9000
	Backdoor    9000
	Trojan      9000
	Ransom      9000
================================================================================
Testing Class Count:
================================================================================
	Worm        1000
	Ransom      1000
	Trojan      1000
	PUA         1000
	Virus       1000
	Backdoor    1000
================================================================================


================================================================================
Begin training...
================================================================================
Using TensorFlow backend.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 512, 1)            0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 449, 100)          6500      
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 44, 100)           0         
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 28, 100)           170100    
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 14, 100)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 13, 100)           20100     
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 6, 100)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 600)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               76928     
_________________________________________________________________
dense_2 (Dense)              (None, 64)                8256      
_________________________________________________________________
dense_3 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_4 (Dense)              (None, 6)                 198       
=================================================================
Total params: 284,162
Trainable params: 284,162
Non-trainable params: 0
_________________________________________________________________
Epoch 1/200
2018-10-29 12:50:23.856868: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-10-29 12:50:27.017354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-10-29 12:50:27.017771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:1e.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-10-29 12:50:27.017798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0
2018-10-29 12:50:27.320323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-10-29 12:50:27.320371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 
2018-10-29 12:50:27.320385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N 
2018-10-29 12:50:27.320746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10759 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
 - 11s - loss: 1.7917 - categorical_accuracy: 0.1732 - acc: 0.1732
Epoch 2/200
 - 5s - loss: 1.7740 - categorical_accuracy: 0.2471 - acc: 0.2471
Epoch 3/200
 - 5s - loss: 1.4667 - categorical_accuracy: 0.3869 - acc: 0.3869
Epoch 4/200
 - 5s - loss: 1.1570 - categorical_accuracy: 0.5164 - acc: 0.5164
Epoch 5/200
 - 5s - loss: 0.9742 - categorical_accuracy: 0.6177 - acc: 0.6177
Epoch 6/200
 - 5s - loss: 0.8536 - categorical_accuracy: 0.6800 - acc: 0.6800
Epoch 7/200
 - 5s - loss: 0.7418 - categorical_accuracy: 0.7370 - acc: 0.7370
Epoch 8/200
 - 5s - loss: 0.6265 - categorical_accuracy: 0.7787 - acc: 0.7787
Epoch 9/200
 - 5s - loss: 0.5473 - categorical_accuracy: 0.8096 - acc: 0.8096
Epoch 10/200
 - 5s - loss: 0.4788 - categorical_accuracy: 0.8340 - acc: 0.8340
Epoch 11/200
 - 5s - loss: 0.4416 - categorical_accuracy: 0.8479 - acc: 0.8479
Epoch 12/200
 - 5s - loss: 0.4081 - categorical_accuracy: 0.8611 - acc: 0.8611
Epoch 13/200
 - 5s - loss: 0.3887 - categorical_accuracy: 0.8676 - acc: 0.8676
Epoch 14/200
 - 5s - loss: 0.3537 - categorical_accuracy: 0.8804 - acc: 0.8804
Epoch 15/200
 - 5s - loss: 0.3289 - categorical_accuracy: 0.8881 - acc: 0.8881
Epoch 16/200
 - 5s - loss: 0.3110 - categorical_accuracy: 0.8939 - acc: 0.8939
Epoch 17/200
 - 5s - loss: 0.3158 - categorical_accuracy: 0.8941 - acc: 0.8941
Epoch 18/200
 - 5s - loss: 0.2688 - categorical_accuracy: 0.9082 - acc: 0.9082
Epoch 19/200
 - 5s - loss: 0.2584 - categorical_accuracy: 0.9119 - acc: 0.9119
Epoch 20/200
 - 5s - loss: 0.2773 - categorical_accuracy: 0.9056 - acc: 0.9056
Epoch 21/200
 - 5s - loss: 0.2356 - categorical_accuracy: 0.9185 - acc: 0.9185
Epoch 22/200
 - 5s - loss: 0.2285 - categorical_accuracy: 0.9213 - acc: 0.9213
Epoch 23/200
 - 5s - loss: 0.2250 - categorical_accuracy: 0.9220 - acc: 0.9220
Epoch 24/200
 - 5s - loss: 0.2566 - categorical_accuracy: 0.9146 - acc: 0.9146
Epoch 25/200
 - 5s - loss: 0.1895 - categorical_accuracy: 0.9341 - acc: 0.9341
Epoch 26/200
 - 5s - loss: 0.1903 - categorical_accuracy: 0.9339 - acc: 0.9339
Epoch 27/200
 - 5s - loss: 0.1890 - categorical_accuracy: 0.9347 - acc: 0.9347
Epoch 28/200
 - 5s - loss: 0.2010 - categorical_accuracy: 0.9297 - acc: 0.9297
Epoch 29/200
 - 5s - loss: 0.1725 - categorical_accuracy: 0.9404 - acc: 0.9404
Epoch 30/200
 - 5s - loss: 0.1691 - categorical_accuracy: 0.9410 - acc: 0.9410
Epoch 31/200
 - 5s - loss: 0.1632 - categorical_accuracy: 0.9429 - acc: 0.9429
Epoch 32/200
 - 5s - loss: 0.1582 - categorical_accuracy: 0.9447 - acc: 0.9447
Epoch 33/200
 - 5s - loss: 0.1488 - categorical_accuracy: 0.9476 - acc: 0.9476
Epoch 34/200
 - 5s - loss: 0.1491 - categorical_accuracy: 0.9485 - acc: 0.9485
Epoch 35/200
 - 5s - loss: 0.1461 - categorical_accuracy: 0.9499 - acc: 0.9499
Epoch 36/200
 - 5s - loss: 0.1349 - categorical_accuracy: 0.9527 - acc: 0.9527
Epoch 37/200
 - 5s - loss: 0.1326 - categorical_accuracy: 0.9535 - acc: 0.9535
Epoch 38/200
 - 5s - loss: 0.1206 - categorical_accuracy: 0.9583 - acc: 0.9583
Epoch 39/200
 - 5s - loss: 0.1899 - categorical_accuracy: 0.9407 - acc: 0.9407
Epoch 40/200
 - 5s - loss: 0.1087 - categorical_accuracy: 0.9621 - acc: 0.9621
Epoch 41/200
 - 5s - loss: 0.1078 - categorical_accuracy: 0.9625 - acc: 0.9625
Epoch 42/200
 - 5s - loss: 0.1689 - categorical_accuracy: 0.9473 - acc: 0.9473
Epoch 43/200
 - 5s - loss: 0.1005 - categorical_accuracy: 0.9647 - acc: 0.9647
Epoch 44/200
 - 5s - loss: 0.0987 - categorical_accuracy: 0.9650 - acc: 0.9650
Epoch 45/200
 - 5s - loss: 0.1016 - categorical_accuracy: 0.9642 - acc: 0.9642
Epoch 46/200
 - 5s - loss: 0.1111 - categorical_accuracy: 0.9608 - acc: 0.9608
Epoch 47/200
 - 5s - loss: 0.0999 - categorical_accuracy: 0.9653 - acc: 0.9653
Epoch 48/200
 - 5s - loss: 0.0983 - categorical_accuracy: 0.9661 - acc: 0.9661
Epoch 49/200
 - 5s - loss: 0.0995 - categorical_accuracy: 0.9652 - acc: 0.9652
Epoch 50/200
 - 5s - loss: 0.0964 - categorical_accuracy: 0.9666 - acc: 0.9666
Epoch 51/200
 - 5s - loss: 0.0883 - categorical_accuracy: 0.9700 - acc: 0.9700
Epoch 52/200
 - 5s - loss: 0.0887 - categorical_accuracy: 0.9694 - acc: 0.9694
Epoch 53/200
 - 5s - loss: 0.0890 - categorical_accuracy: 0.9691 - acc: 0.9691
Epoch 54/200
 - 5s - loss: 0.1499 - categorical_accuracy: 0.9569 - acc: 0.9569
Epoch 55/200
 - 5s - loss: 0.0727 - categorical_accuracy: 0.9747 - acc: 0.9747
Epoch 56/200
 - 5s - loss: 0.0743 - categorical_accuracy: 0.9747 - acc: 0.9747
Epoch 57/200
 - 5s - loss: 0.0761 - categorical_accuracy: 0.9739 - acc: 0.9739
Epoch 58/200
 - 5s - loss: 0.0810 - categorical_accuracy: 0.9728 - acc: 0.9728
Epoch 59/200
 - 5s - loss: 0.0785 - categorical_accuracy: 0.9741 - acc: 0.9741
Epoch 60/200
 - 5s - loss: 0.0752 - categorical_accuracy: 0.9739 - acc: 0.9739
Epoch 61/200
 - 5s - loss: 0.0787 - categorical_accuracy: 0.9724 - acc: 0.9724
Epoch 62/200
 - 5s - loss: 0.0708 - categorical_accuracy: 0.9753 - acc: 0.9753
Epoch 63/200
 - 5s - loss: 0.0696 - categorical_accuracy: 0.9763 - acc: 0.9763
Epoch 64/200
 - 5s - loss: 0.0710 - categorical_accuracy: 0.9760 - acc: 0.9760
Epoch 65/200
 - 5s - loss: 0.0638 - categorical_accuracy: 0.9791 - acc: 0.9791
Epoch 66/200
 - 5s - loss: 0.0696 - categorical_accuracy: 0.9764 - acc: 0.9764
Epoch 67/200
 - 5s - loss: 0.0962 - categorical_accuracy: 0.9695 - acc: 0.9695
Epoch 68/200
 - 5s - loss: 0.0577 - categorical_accuracy: 0.9811 - acc: 0.9811
Epoch 69/200
 - 5s - loss: 0.0543 - categorical_accuracy: 0.9817 - acc: 0.9817
Epoch 70/200
 - 5s - loss: 0.0592 - categorical_accuracy: 0.9801 - acc: 0.9801
Epoch 71/200
 - 5s - loss: 0.0620 - categorical_accuracy: 0.9792 - acc: 0.9792
Epoch 72/200
 - 5s - loss: 0.0612 - categorical_accuracy: 0.9795 - acc: 0.9795
Epoch 73/200
 - 5s - loss: 0.0602 - categorical_accuracy: 0.9799 - acc: 0.9799
Epoch 74/200
 - 5s - loss: 0.0558 - categorical_accuracy: 0.9806 - acc: 0.9806
Epoch 75/200
 - 5s - loss: 0.0575 - categorical_accuracy: 0.9806 - acc: 0.9806
Epoch 76/200
 - 5s - loss: 0.0571 - categorical_accuracy: 0.9808 - acc: 0.9808
Epoch 77/200
 - 5s - loss: 0.0666 - categorical_accuracy: 0.9783 - acc: 0.9783
Epoch 78/200
 - 5s - loss: 0.0488 - categorical_accuracy: 0.9838 - acc: 0.9838
Epoch 79/200
 - 5s - loss: 0.0484 - categorical_accuracy: 0.9836 - acc: 0.9836
Epoch 80/200
 - 5s - loss: 0.0599 - categorical_accuracy: 0.9797 - acc: 0.9797
Epoch 81/200
 - 5s - loss: 0.0545 - categorical_accuracy: 0.9816 - acc: 0.9816
Epoch 82/200
 - 5s - loss: 0.0510 - categorical_accuracy: 0.9834 - acc: 0.9834
Epoch 83/200
 - 5s - loss: 0.0513 - categorical_accuracy: 0.9829 - acc: 0.9829
Epoch 84/200
 - 5s - loss: 0.0464 - categorical_accuracy: 0.9844 - acc: 0.9844
Epoch 85/200
 - 5s - loss: 0.0554 - categorical_accuracy: 0.9811 - acc: 0.9811
Epoch 86/200
 - 5s - loss: 0.0488 - categorical_accuracy: 0.9840 - acc: 0.9840
Epoch 87/200
 - 5s - loss: 0.0430 - categorical_accuracy: 0.9859 - acc: 0.9859
Epoch 88/200
 - 5s - loss: 0.0424 - categorical_accuracy: 0.9859 - acc: 0.9859
Epoch 89/200
 - 5s - loss: 0.0558 - categorical_accuracy: 0.9820 - acc: 0.9820
Epoch 90/200
 - 5s - loss: 0.0400 - categorical_accuracy: 0.9868 - acc: 0.9868
Epoch 91/200
 - 5s - loss: 0.0428 - categorical_accuracy: 0.9852 - acc: 0.9852
Epoch 92/200
 - 5s - loss: 0.0453 - categorical_accuracy: 0.9849 - acc: 0.9849
Epoch 93/200
 - 5s - loss: 0.0422 - categorical_accuracy: 0.9860 - acc: 0.9860
Epoch 94/200
 - 5s - loss: 0.0447 - categorical_accuracy: 0.9852 - acc: 0.9852
Epoch 95/200
 - 5s - loss: 0.0429 - categorical_accuracy: 0.9858 - acc: 0.9858
Epoch 96/200
 - 5s - loss: 0.0409 - categorical_accuracy: 0.9860 - acc: 0.9860
Epoch 97/200
 - 5s - loss: 0.0364 - categorical_accuracy: 0.9879 - acc: 0.9879
Epoch 98/200
 - 5s - loss: 0.0552 - categorical_accuracy: 0.9825 - acc: 0.9825
Epoch 99/200
 - 5s - loss: 0.0337 - categorical_accuracy: 0.9892 - acc: 0.9892
Epoch 100/200
 - 5s - loss: 0.0328 - categorical_accuracy: 0.9889 - acc: 0.9889
Epoch 101/200
 - 5s - loss: 0.0384 - categorical_accuracy: 0.9871 - acc: 0.9871
Epoch 102/200
 - 5s - loss: 0.0414 - categorical_accuracy: 0.9864 - acc: 0.9864
Epoch 103/200
 - 5s - loss: 0.0413 - categorical_accuracy: 0.9865 - acc: 0.9865
Epoch 104/200
 - 5s - loss: 0.0346 - categorical_accuracy: 0.9887 - acc: 0.9887
Epoch 105/200
 - 5s - loss: 0.0389 - categorical_accuracy: 0.9873 - acc: 0.9873
Epoch 106/200
 - 5s - loss: 0.0404 - categorical_accuracy: 0.9864 - acc: 0.9864
Epoch 107/200
 - 5s - loss: 0.0321 - categorical_accuracy: 0.9894 - acc: 0.9894
Epoch 108/200
 - 5s - loss: 0.0331 - categorical_accuracy: 0.9891 - acc: 0.9891
Epoch 109/200
 - 5s - loss: 0.0325 - categorical_accuracy: 0.9892 - acc: 0.9892
Epoch 110/200
 - 5s - loss: 0.0364 - categorical_accuracy: 0.9880 - acc: 0.9880
Epoch 111/200
 - 5s - loss: 0.0329 - categorical_accuracy: 0.9892 - acc: 0.9892
Epoch 112/200
 - 5s - loss: 0.0339 - categorical_accuracy: 0.9892 - acc: 0.9892
Epoch 113/200
 - 5s - loss: 0.0317 - categorical_accuracy: 0.9893 - acc: 0.9893
Epoch 114/200
 - 5s - loss: 0.0408 - categorical_accuracy: 0.9868 - acc: 0.9868
Epoch 115/200
 - 5s - loss: 0.0317 - categorical_accuracy: 0.9896 - acc: 0.9896
Epoch 116/200
 - 5s - loss: 0.0298 - categorical_accuracy: 0.9905 - acc: 0.9905
Epoch 117/200
 - 5s - loss: 0.1794 - categorical_accuracy: 0.9653 - acc: 0.9653
Epoch 118/200
 - 5s - loss: 0.0352 - categorical_accuracy: 0.9887 - acc: 0.9887
Epoch 119/200
 - 5s - loss: 0.0244 - categorical_accuracy: 0.9922 - acc: 0.9922
Epoch 120/200
 - 5s - loss: 0.0270 - categorical_accuracy: 0.9911 - acc: 0.9911
Epoch 121/200
 - 5s - loss: 0.0285 - categorical_accuracy: 0.9909 - acc: 0.9909
Epoch 122/200
 - 5s - loss: 0.0776 - categorical_accuracy: 0.9779 - acc: 0.9779
Epoch 123/200
 - 5s - loss: 0.0289 - categorical_accuracy: 0.9908 - acc: 0.9908
Epoch 124/200
 - 5s - loss: 0.0243 - categorical_accuracy: 0.9923 - acc: 0.9923
Epoch 125/200
 - 5s - loss: 0.0280 - categorical_accuracy: 0.9909 - acc: 0.9909
Epoch 126/200
 - 5s - loss: 0.0262 - categorical_accuracy: 0.9913 - acc: 0.9913
Epoch 127/200
 - 5s - loss: 0.0376 - categorical_accuracy: 0.9882 - acc: 0.9882
Epoch 128/200
 - 5s - loss: 0.0255 - categorical_accuracy: 0.9916 - acc: 0.9916
Epoch 129/200
 - 5s - loss: 0.0283 - categorical_accuracy: 0.9906 - acc: 0.9906
Epoch 130/200
 - 5s - loss: 0.0306 - categorical_accuracy: 0.9898 - acc: 0.9898
Epoch 131/200
 - 5s - loss: 0.0296 - categorical_accuracy: 0.9902 - acc: 0.9902
Epoch 132/200
 - 5s - loss: 0.0246 - categorical_accuracy: 0.9917 - acc: 0.9917
Epoch 133/200
 - 5s - loss: 0.0229 - categorical_accuracy: 0.9925 - acc: 0.9925
Epoch 134/200
 - 5s - loss: 0.0262 - categorical_accuracy: 0.9913 - acc: 0.9913
Epoch 135/200
 - 5s - loss: 0.0257 - categorical_accuracy: 0.9914 - acc: 0.9914
Epoch 136/200
 - 5s - loss: 0.0282 - categorical_accuracy: 0.9908 - acc: 0.9908
Epoch 137/200
 - 5s - loss: 0.0245 - categorical_accuracy: 0.9917 - acc: 0.9917
Epoch 138/200
 - 5s - loss: 0.0246 - categorical_accuracy: 0.9920 - acc: 0.9920
Epoch 139/200
 - 5s - loss: 0.0263 - categorical_accuracy: 0.9913 - acc: 0.9913
Epoch 140/200
 - 5s - loss: 0.0262 - categorical_accuracy: 0.9917 - acc: 0.9917
Epoch 141/200
 - 5s - loss: 0.0214 - categorical_accuracy: 0.9928 - acc: 0.9928
Epoch 142/200
 - 5s - loss: 0.0268 - categorical_accuracy: 0.9909 - acc: 0.9909
Epoch 143/200
 - 5s - loss: 0.0234 - categorical_accuracy: 0.9921 - acc: 0.9921
Epoch 144/200
 - 5s - loss: 0.0236 - categorical_accuracy: 0.9923 - acc: 0.9923
Epoch 145/200
 - 5s - loss: 0.1054 - categorical_accuracy: 0.9758 - acc: 0.9758
Epoch 146/200
 - 5s - loss: 0.0230 - categorical_accuracy: 0.9929 - acc: 0.9929
Epoch 147/200
 - 5s - loss: 0.0176 - categorical_accuracy: 0.9945 - acc: 0.9945
Epoch 148/200
 - 5s - loss: 0.0182 - categorical_accuracy: 0.9940 - acc: 0.9940
Epoch 149/200
 - 5s - loss: 0.0239 - categorical_accuracy: 0.9921 - acc: 0.9921
Epoch 150/200
 - 5s - loss: 0.0260 - categorical_accuracy: 0.9913 - acc: 0.9913
Epoch 151/200
 - 5s - loss: 0.0255 - categorical_accuracy: 0.9914 - acc: 0.9914
Epoch 152/200
 - 5s - loss: 0.0240 - categorical_accuracy: 0.9924 - acc: 0.9924
Epoch 153/200
 - 5s - loss: 0.0246 - categorical_accuracy: 0.9917 - acc: 0.9917
Epoch 154/200
 - 5s - loss: 0.0212 - categorical_accuracy: 0.9932 - acc: 0.9932
Epoch 155/200
 - 5s - loss: 0.0217 - categorical_accuracy: 0.9929 - acc: 0.9929
Epoch 156/200
 - 5s - loss: 0.0199 - categorical_accuracy: 0.9933 - acc: 0.9933
Epoch 157/200
 - 5s - loss: 0.0190 - categorical_accuracy: 0.9940 - acc: 0.9940
Epoch 158/200
 - 5s - loss: 0.0218 - categorical_accuracy: 0.9930 - acc: 0.9930
Epoch 159/200
 - 5s - loss: 0.0224 - categorical_accuracy: 0.9928 - acc: 0.9928
Epoch 160/200
 - 5s - loss: 0.0321 - categorical_accuracy: 0.9903 - acc: 0.9903
Epoch 161/200
 - 5s - loss: 0.0193 - categorical_accuracy: 0.9938 - acc: 0.9938
Epoch 162/200
 - 5s - loss: 0.0205 - categorical_accuracy: 0.9931 - acc: 0.9931
Epoch 163/200
 - 5s - loss: 0.0216 - categorical_accuracy: 0.9930 - acc: 0.9930
Epoch 164/200
 - 5s - loss: 0.0279 - categorical_accuracy: 0.9910 - acc: 0.9910
Epoch 165/200
 - 5s - loss: 0.0154 - categorical_accuracy: 0.9951 - acc: 0.9951
Epoch 166/200
 - 5s - loss: 0.0153 - categorical_accuracy: 0.9951 - acc: 0.9951
Epoch 167/200
 - 5s - loss: 0.0216 - categorical_accuracy: 0.9927 - acc: 0.9927
Epoch 168/200
 - 5s - loss: 0.0206 - categorical_accuracy: 0.9937 - acc: 0.9937
Epoch 169/200
 - 5s - loss: 0.0190 - categorical_accuracy: 0.9940 - acc: 0.9940
Epoch 170/200
 - 5s - loss: 0.0178 - categorical_accuracy: 0.9943 - acc: 0.9943
Epoch 171/200
 - 5s - loss: 0.0159 - categorical_accuracy: 0.9948 - acc: 0.9948
Epoch 172/200
 - 5s - loss: 0.0176 - categorical_accuracy: 0.9942 - acc: 0.9942
Epoch 173/200
 - 5s - loss: 0.0202 - categorical_accuracy: 0.9935 - acc: 0.9935
Epoch 174/200
 - 5s - loss: 0.0211 - categorical_accuracy: 0.9931 - acc: 0.9931
Epoch 175/200
 - 5s - loss: 0.0183 - categorical_accuracy: 0.9943 - acc: 0.9943
Epoch 176/200
 - 5s - loss: 0.0178 - categorical_accuracy: 0.9943 - acc: 0.9943
Epoch 177/200
 - 5s - loss: 0.0166 - categorical_accuracy: 0.9948 - acc: 0.9948
Epoch 178/200
 - 5s - loss: 0.0224 - categorical_accuracy: 0.9931 - acc: 0.9931
Epoch 179/200
 - 5s - loss: 0.0152 - categorical_accuracy: 0.9950 - acc: 0.9950
Epoch 180/200
 - 5s - loss: 0.0160 - categorical_accuracy: 0.9946 - acc: 0.9946
Epoch 181/200
 - 5s - loss: 0.0165 - categorical_accuracy: 0.9944 - acc: 0.9944
Epoch 182/200
 - 5s - loss: 0.0256 - categorical_accuracy: 0.9920 - acc: 0.9920
Epoch 183/200
 - 5s - loss: 0.0440 - categorical_accuracy: 0.9883 - acc: 0.9883
Epoch 184/200
 - 5s - loss: 0.0122 - categorical_accuracy: 0.9961 - acc: 0.9961
Epoch 185/200
 - 5s - loss: 0.0155 - categorical_accuracy: 0.9950 - acc: 0.9950
Epoch 186/200
 - 5s - loss: 0.0234 - categorical_accuracy: 0.9931 - acc: 0.9931
Epoch 187/200
 - 5s - loss: 0.0236 - categorical_accuracy: 0.9924 - acc: 0.9924
Epoch 188/200
 - 5s - loss: 0.0133 - categorical_accuracy: 0.9956 - acc: 0.9956
Epoch 189/200
 - 5s - loss: 0.0382 - categorical_accuracy: 0.9896 - acc: 0.9896
Epoch 190/200
 - 5s - loss: 0.0196 - categorical_accuracy: 0.9938 - acc: 0.9938
Epoch 191/200
 - 5s - loss: 0.0129 - categorical_accuracy: 0.9959 - acc: 0.9959
Epoch 192/200
 - 5s - loss: 0.0174 - categorical_accuracy: 0.9941 - acc: 0.9941
Epoch 193/200
 - 5s - loss: 0.0118 - categorical_accuracy: 0.9962 - acc: 0.9962
Epoch 194/200
 - 5s - loss: 0.0156 - categorical_accuracy: 0.9948 - acc: 0.9948
Epoch 195/200
 - 5s - loss: 0.0191 - categorical_accuracy: 0.9936 - acc: 0.9936
Epoch 196/200
 - 5s - loss: 0.0242 - categorical_accuracy: 0.9920 - acc: 0.9920
Epoch 197/200
 - 5s - loss: 0.0176 - categorical_accuracy: 0.9945 - acc: 0.9945
Epoch 198/200
 - 5s - loss: 0.0162 - categorical_accuracy: 0.9948 - acc: 0.9948
Epoch 199/200
 - 5s - loss: 0.0144 - categorical_accuracy: 0.9954 - acc: 0.9954
Epoch 200/200
 - 5s - loss: 0.0129 - categorical_accuracy: 0.9958 - acc: 0.9958
Training time 1076.077963 seconds
================================================================================


================================================================================
Confusion Matrix:
[[964  10   6  15   2   3]
 [ 10 931  12  35   5   7]
 [  3  20 928  31  10   8]
 [ 12  35  40 881  17  15]
 [  3   6  10  11 968   2]
 [  4   4  10  14   7 961]]
================================================================================
	Accuracy:
	0.9388333333333333
================================================================================
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
  if diff:
Saving the figure as cnn_rwe_256_512.png...


================================================================================
Saving the classifier...
Classifier saved to: /mnt/data/RWE/classifiers/classifiers_rwe_256_window_512_datapoints/cnn
================================================================================


